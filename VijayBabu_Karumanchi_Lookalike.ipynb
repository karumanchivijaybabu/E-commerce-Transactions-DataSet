{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "import pandas as pd\n",
    "\n",
    "customers = pd.read_csv('Customers.csv')\n",
    "products = pd.read_csv('Products.csv')\n",
    "transactions = pd.read_csv('Transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID      0\n",
      "CustomerName    0\n",
      "Region          0\n",
      "SignupDate      0\n",
      "dtype: int64\n",
      "ProductID      0\n",
      "ProductName    0\n",
      "Category       0\n",
      "Price          0\n",
      "dtype: int64\n",
      "TransactionID      0\n",
      "CustomerID         0\n",
      "ProductID          0\n",
      "TransactionDate    0\n",
      "Quantity           0\n",
      "TotalValue         0\n",
      "Price              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Cleaning data\n",
    "#Check for missing values\n",
    "print(customers.isnull().sum())\n",
    "print(products.isnull().sum())\n",
    "print(transactions.isnull().sum())\n",
    "#handle Duplicates and inconsistent data\n",
    "customers.drop_duplicates(inplace=True)\n",
    "products.drop_duplicates(inplace=True)\n",
    "transactions.drop_duplicates(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine datasets\n",
    "# Merge Transactions.csv and Customers.csv on CustomerID.\n",
    "# Merge the result with Products.csv on ProductID.\n",
    "customer_transactions = pd.merge(transactions, customers, on='CustomerID')\n",
    "customer_transactions = pd.merge(customer_transactions, products, on='ProductID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Features\n",
    "# Use relevant features like Region, TotalValue, Category, etc., to describe customer profiles.\n",
    "# Optionally, encode categorical variables (e.g., Region, Category) using one-hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoded_region = encoder.fit_transform(customer_transactions[['Region']]).toarray()\n",
    "customer_transactions = pd.concat(\n",
    "    [customer_transactions, pd.DataFrame(encoded_region, columns=encoder.categories_[0])], axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Aggregation\n",
    "# Aggregate data by CustomerID to create a single row per customer. For example:\n",
    "# Total spending (TotalValue).\n",
    "# Number of unique categories purchased.\n",
    "# Average quantity per transaction.\n",
    "customer_features = customer_transactions.groupby('CustomerID').agg({\n",
    "    'TotalValue': 'sum',\n",
    "    'Category': 'nunique',\n",
    "    'Quantity': 'mean'\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute Similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(customer_features.drop(columns=['CustomerID']))\n",
    "#Calculate PairWise Similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = cosine_similarity(normalized_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the first 20 customers\n",
    "first_20_customers = customer_features.iloc[:20]\n",
    "# Get Reommendations for first 20 customers\n",
    "def get_top_n_similarities_for_subset(similarity_matrix, customer_subset, n=3):\n",
    "    recommendations = {}\n",
    "    for i in range(len(customer_subset)):\n",
    "        similar_indices = np.argsort(similarity_matrix[i])[::-1][1:n+1]\n",
    "        recommendations[customer_subset['CustomerID'].iloc[i]] = [\n",
    "            (customer_subset['CustomerID'].iloc[j], similarity_matrix[i][j]) for j in similar_indices\n",
    "        ]\n",
    "    return recommendations\n",
    "\n",
    "# Generate similarity matrix for the first 20 customers\n",
    "subset_features = normalized_features[:20]\n",
    "subset_similarity_matrix = cosine_similarity(subset_features)\n",
    "recommendations = get_top_n_similarities_for_subset(subset_similarity_matrix, first_20_customers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Recommendations to CSV\n",
    "\n",
    "with open('VijayBabu_Karumanchi_Lookalike.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['CustomerID', 'Recommendations'])\n",
    "    for customer_id, recs in recommendations.items():\n",
    "        writer.writerow([customer_id, recs])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
